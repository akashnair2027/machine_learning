{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb09c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a52db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776c5ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af21bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4aa92f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0085f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a380af10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be26f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7783879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3952334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f744526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7cd17dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11a0b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20900\\3579200346.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['review'] = df['review'].str.replace(r'<.*?>','')\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].str.replace(r'<.*?>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c330205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0435736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern =re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa029ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of come'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags('A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of come')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53105333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99753551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data):\n",
    "    data = re.sub(r\"https?://\\S+|www.\\.S+\",'',data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd8ef209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20900\\1187195537.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['review'] = df['review'].str.replace(r\"https?://\\S+|www.\\.S+\",'')\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].str.replace(r\"https?://\\S+|www.\\.S+\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e558c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data,https?:/??? kya search kar reh ho ashwini meraa copy mat karo '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url('data,https?:/??? kya search kar reh ho ashwini meraa copy mat karo ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feba9a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b6a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce64e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text =text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1099832",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'string. with. punctuation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ebbba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string with punctuation'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c62f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string with punctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 =time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66492b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_pu(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e997c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string with punctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "print(re_pu(text))\n",
    "time1 = time.time() -  start1\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d1bb03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3935d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (text):\n",
    "    nt = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            nt.append('')\n",
    "        else:\n",
    "            nt.append(word)\n",
    "    x = nt[:]\n",
    "    nt.clear()\n",
    "    return \" \".join(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bbe20cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name  python  iam fine'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('My name is python and iam fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a6ba52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f301f",
   "metadata": {},
   "source": [
    "CHAT WORD HANDLING:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "680a3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa6af285",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ebed68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one minute, For Your Information'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_map_dict = {}\n",
    "chat_words_list =[]\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line !=\"\":\n",
    "        cw=line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw]=cw_expanded\n",
    "chat_words_list=set(chat_words_list)\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "chat_words_conversion('one minute, FYI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec9513c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from TextBlob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->TextBlob) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43853ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95799a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect ='certaiiin conditionss from ggnerationas are modified in the same maner\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8413373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions from generations are modified in the same manner\"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt =TextBlob(incorrect)\n",
    "txt.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51ed400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(text):\n",
    "    return TextBlob(text).correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc03e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7568d226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    One of the other reviews has mentioned that af...\n",
       "1    A wonderful little production. The filling tec...\n",
       "2    I thought this was a wonderful way to spend ti...\n",
       "3    Basically there's a family where a little boy ...\n",
       "4    Letter Matter's \"Love in the Time of Money\" is...\n",
       "5    Probably my all-time favorite movie, a story o...\n",
       "6    I sure would like to see a resurrection of a u...\n",
       "7    His show was an amazing, fresh & innovative id...\n",
       "8    Encouraged by the positive comments about this...\n",
       "9    Of you like original gut wrenching laughter yo...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(spelling_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ac7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling emojis\n",
    "\n",
    "# Remove \n",
    "# Replace the emoji with its meaning\n",
    "\n",
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" #emotions\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" #sumbols and pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" #transport and map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" #flags\n",
    "                           u\"\\U00002702-\\U000027B0\"  \n",
    "                           u\"\\U000024C2-\\U0001F251\"  \n",
    " \n",
    "                           \"]+\",flags = re.UNICODE)\n",
    "    return  emoji_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95b143fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is fun '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji('Python is fun ‚ù§Ô∏è')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d58702cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74808573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÇ\n",
      "üòÖ\n",
      "üòç\n",
      "ü§™\n",
      "ü§´\n"
     ]
    }
   ],
   "source": [
    "print('\\U0001F602')\n",
    "print('\\U0001F605')\n",
    "print('\\U0001F60D')\n",
    "print('\\U0001F92A')\n",
    "print('\\U0001F92B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8c94f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emoji' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20900\\862958315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python is :thumbs_up:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python is :thumbsup:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'alias'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python is üëç'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Python is fun :red_heart:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emoji' is not defined"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize('Python is :thumbs_up:'))\n",
    "\n",
    "print(emoji.emojize('Python is :thumbsup:', language='alias'))\n",
    "print(emoji.demojize('Python is üëç'))\n",
    "print(emoji.emojize(\"Python is fun :red_heart:\"))\n",
    "print(emoji.emojize(\"Python is fun :red_heart:\", variant=\"emoji_type\"))\n",
    "print(emoji.is_emoji(\"üëç\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e6ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380dcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d6dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b37f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac884115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b290ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed307fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cd7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94a9da79",
   "metadata": {},
   "outputs": [],
   "source": [
    " from nltk.stem.porter import  PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5cba0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5e4c28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \" walk walks walkings walked\"\n",
    "stem(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e531ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the center of the storm will push northeastward while remain just offshor into monday evening. becaus of thi track, the worst condit from the storm will hold off, but onli for so long.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"The center of the storm will push northeastward while remaining just offshore into Monday evening. Because of this track, the worst conditions from the storm will hold off, but only for so long.\"\n",
    "stem(text1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e62d476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3caf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4231e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kites --->Kites\n",
      "babies --->baby\n",
      "dogs --->dog\n",
      "flying --->flying\n",
      "smiling --->smiling\n",
      "driving --->driving\n",
      "died --->died\n",
      "tried --->tried\n",
      "feet --->foot\n"
     ]
    }
   ],
   "source": [
    "list1 = ['Kites', 'babies', 'dogs','flying','smiling','driving','died','tried','feet']\n",
    "for words in list1:\n",
    "    print(words + \" --->\" + wnl.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6ad86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence  lemmatization examples\n",
    "string = 'the cat is sitting with the bats on the striped mat under many flying geese'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f24bfea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'is', 'sitting', 'with', 'the', 'bats', 'on', 'the', 'striped', 'mat', 'under', 'many', 'flying', 'geese']\n",
      "the cat is sitting with the bat on the striped mat under many flying goose\n"
     ]
    }
   ],
   "source": [
    "# converting string  into tokens\n",
    "list2 = nltk.word_tokenize(string)\n",
    "print(list2)\n",
    "#['the','cat', 'is,', 'sitting','with',' the',' bats', 'on', \n",
    " #'the', 'striped', 'mat', 'under', 'many', 'flying', 'geese,]\n",
    "lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "\n",
    "print(lemmatized_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c92fb7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d04e170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'), ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('badly', 'RB'), ('flying', 'VBG'), ('geese', 'JJ')]\n",
      "[('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None), ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'), ('mat', 'n'), ('under', None), ('many', 'a'), ('badly', 'r'), ('flying', 'v'), ('geese', 'a')]\n",
      "the cat be sit with the bat on the striped mat under many badly fly geese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_percepttron_tagger: Package\n",
      "[nltk_data]     'averaged_percepttron_tagger' not found in index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_percepttron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Define function to lemmatize each word with its POS tag\n",
    " \n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "         return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "sentence ='the cat is sitting with the bats on the striped mat under many badly flying geese'\n",
    "# tokenize the sentence and find the POS tag for each token\n",
    "pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "print(pos_tagged)\n",
    "\n",
    "\n",
    "wordnet_tagged = list(map(lambda x: (x[0],pos_tagger(x[1])),pos_tagged))\n",
    "print(wordnet_tagged)\n",
    " \n",
    "lemmatized_sentence = []\n",
    "for word, tag in wordnet_tagged:\n",
    "    if tag is None:\n",
    "        lemmatized_sentence.append(word)\n",
    "    else:\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word,tag))\n",
    "lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "print(lemmatized_sentence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298a2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c547c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c0c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0269d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eb238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13e467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884310cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
